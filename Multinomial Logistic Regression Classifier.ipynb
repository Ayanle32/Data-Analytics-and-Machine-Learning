{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74bdde8a",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "Softmax Regression allows Logistic Regression to be generalised to support multiple classes. Given an instance $\\bf{x}$, the Softmax model computes a score for each class k\n",
    "\n",
    "$\\Large s_k(\\bf{x}) = \\bf{x}^T\\bf{\\theta}^{(k)}$.\n",
    "\n",
    "The probability of each class is then computed using the softmax function\n",
    "\n",
    "$\\Large \\hat{p}_k = \\sigma(\\bf{s}(\\bf{x}))_k = \\frac{\\exp(s_k(\\bf{x}))}{\\sum_{j=1}^{K}\\exp(s_j(\\bf{x}))} $\n",
    "\n",
    "The Softmax Regression classifier predicts the class with the highest estimated probability which is the class with the highest score.\n",
    "\n",
    "$\\Large \\hat{y} =$ argmax $\\Large \\sigma(\\bf{s}(\\bf{x}))_k =$ argmax $\\Large s_k(\\bf{x}) = $ argmax $\\Large \\left((\\bf{\\theta}^{(k)})^T\\bf{x}\\right)$\n",
    "\n",
    "## Cost Function\n",
    "\n",
    "The generalised cost function for multinomial Logistic Regression is the cross-entropy\n",
    "\n",
    "$\\Large J(\\bf{\\theta}) = -\\frac{1}{m}\\sum_{i = 1}^{m}\\sum_{j = 1}^{k=K}y_{k}^{(i)}\\log\\left(\\hat{p}_{k}^{(i)}\\right)$\n",
    "\n",
    "when k=2 this becomes the log-loss cost function of binary logistic regression.\n",
    "\n",
    "The gradient vector of this cost function with respect to $\\bf{\\theta}^{(k)}$\n",
    "\n",
    "$\\Large \\nabla_{\\bf{\\theta}^{(k)}}J(\\bf{\\theta}) = \\frac{1}{m}\\sum_{i=1}^{m}\\left(\\hat{p}_{k}^{(i)} - y_{k}^{(i)}\\right)\\bf{x}^{(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57748588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ae86405",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, theta = None, epochs = 1000, learning_rate = 0.01):\n",
    "        self.theta = theta\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "   \n",
    "    def softmax(self, s):\n",
    "        s = s - np.max(s, axis=1, keepdims=True) # To prevent the exponential overloading\n",
    "        prob = np.exp(s) / np.sum(np.exp(s), axis=1, keepdims=True)\n",
    "        return prob\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        X_b = np.c_[np.ones((m, 1)), X] # include a column of ones for the bias term\n",
    "        k = len(np.unique(y)) # number of classes\n",
    "        self.theta = np.random.randn(n+1, k) # initalise the weight vector\n",
    "        y_one_hot = np.zeros((m, k))\n",
    "        y_one_hot[np.arange(m), y] = 1\n",
    "        for i in range(self.epochs):\n",
    "            s = X_b.T.dot(self.theta)\n",
    "            gradients = 1/m * X_b.T.dot(self.softmax(s) - y_one_hot)\n",
    "            self.theta -= self.learning_rate*gradients\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        m = X.shape[0]\n",
    "        X_b = np.c_[np.ones((m, 1)), X]\n",
    "        y_pred = self.softmax(X_b.dot(self.theta))\n",
    "        return np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87bdcebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad9141ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccaf09e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = iris[:, 2:3]\n",
    "target = load_iris().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0a6b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e934d91",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,150) and (2,3) not aligned: 150 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19364/3810562061.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlog_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19364/1927971538.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0my_one_hot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_b\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX_b\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_one_hot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,150) and (2,3) not aligned: 150 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "log_reg.fit(pl, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f2fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.predict([[1.2], [3.2], [5.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b8da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = np.zeros((150, 3))\n",
    "#y_one_hot[np.arange(150), y] = 1\n",
    "y_one_hot[np.arange(150), target] = 1\n",
    "y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5f4b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebb097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
