{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74bdde8a",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "Softmax Regression allows Logistic Regression to be generalised to support multiple classes. Given an instance $\\bf{x}$, the Softmax model computes a score for each class k\n",
    "\n",
    "$\\Large s_k(\\bf{x}) = \\bf{x}^T\\bf{\\theta}^{(k)}$.\n",
    "\n",
    "The probability of each class is then computed using the softmax function\n",
    "\n",
    "$\\Large \\hat{p}_k = \\sigma(\\bf{s}(\\bf{x}))_k = \\frac{\\exp(s_k(\\bf{x}))}{\\sum_{j=1}^{K}\\exp(s_j(\\bf{x}))} $\n",
    "\n",
    "The Softmax Regression classifier predicts the class with the highest estimated probability which is the class with the highest score.\n",
    "\n",
    "$\\Large \\hat{y} =$ argmax $\\Large \\sigma(\\bf{s}(\\bf{x}))_k =$ argmax $\\Large s_k(\\bf{x}) = $ argmax $\\Large \\left((\\bf{\\theta}^{(k)})^T\\bf{x}\\right)$\n",
    "\n",
    "## Cost Function\n",
    "\n",
    "The generalised cost function for multinomial Logistic Regression is the cross-entropy\n",
    "\n",
    "$\\Large J(\\bf{\\theta}) = -\\frac{1}{m}\\sum_{i = 1}^{m}\\sum_{j = 1}^{k=K}y_{k}^{(i)}\\log\\left(\\hat{p}_{k}^{(i)}\\right)$\n",
    "\n",
    "when k=2 this becomes the log-loss cost function of binary logistic regression.\n",
    "\n",
    "The gradient vector of this cost function with respect to $\\bf{\\theta}^{(k)}$\n",
    "\n",
    "$\\Large \\nabla_{\\bf{\\theta}^{(k)}}J(\\bf{\\theta}) = \\frac{1}{m}\\sum_{i=1}^{m}\\left(\\hat{p}_{k}^{(i)} - y_{k}^{(i)}\\right)\\bf{x}^{(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57748588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "9ae86405",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, theta = None, epochs = 1000, learning_rate = 0.01):\n",
    "        self.theta = theta\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "   \n",
    "    def softmax(self, s):\n",
    "        s = s - np.max(s, axis=1, keepdims=True) # To prevent the exponential overloading\n",
    "        prob = np.exp(s) / np.sum(np.exp(s), axis=1, keepdims=True)\n",
    "        return prob\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        X_b = np.c_[np.ones((m, 1)), X] # include a column of ones for the bias term\n",
    "        k = len(np.unique(y)) # number of classes\n",
    "        self.theta = np.random.randn(n+1, k) # initalise the weight vector\n",
    "        y_one_hot = np.zeros((m, k))\n",
    "        y_one_hot[np.arange(m), y] = 1\n",
    "        for i in range(self.epochs):\n",
    "            s = X_b.dot(self.theta)\n",
    "            gradients = 1/m * X_b.T.dot(self.softmax(s) - y_one_hot)\n",
    "            self.theta -= self.learning_rate*gradients\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        m = X.shape[0]\n",
    "        X_b = np.c_[np.ones((m, 1)), X]\n",
    "        y_pred = self.softmax(X_b.dot(self.theta))\n",
    "        return np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87bdcebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad9141ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccaf09e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = iris[:, 2:3]\n",
    "target = load_iris().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "c0a6b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "2e934d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.fit(pl, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "4d4f2fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict([[1.2], [3.2], [5.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82b8da1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot = np.zeros((150, 3))\n",
    "#y_one_hot[np.arange(150), y] = 1\n",
    "y_one_hot[np.arange(150), target] = 1\n",
    "y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b5f4b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebb097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
